{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utils\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "genres = utils.load('data/fma_metadata/genres.csv')\n",
    "features = utils.load('data/fma_metadata/features.csv')\n",
    "small = tracks[tracks['set', 'subset'] <= 'small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            album                                                          \\\n",
      "         comments        date_created date_released engineer favorites id   \n",
      "track_id                                                                    \n",
      "2               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
      "3               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
      "5               0 2008-11-26 01:44:45    2009-01-05      NaN         4  1   \n",
      "10              0 2008-11-26 01:45:08    2008-02-06      NaN         4  6   \n",
      "20              0 2008-11-26 01:45:05    2009-01-06      NaN         2  4   \n",
      "\n",
      "                                                                           \\\n",
      "                                        information listens producer tags   \n",
      "track_id                                                                    \n",
      "2                                           <p></p>    6073      NaN   []   \n",
      "3                                           <p></p>    6073      NaN   []   \n",
      "5                                           <p></p>    6073      NaN   []   \n",
      "10                                              NaN   47632      NaN   []   \n",
      "20        <p>Â \"spiritual songs\" from Nicky Cook</p>    2710      NaN   []   \n",
      "\n",
      "          ...       track                         \\\n",
      "          ... information interest language_code   \n",
      "track_id  ...                                      \n",
      "2         ...         NaN     4656            en   \n",
      "3         ...         NaN     1470            en   \n",
      "5         ...         NaN     1933            en   \n",
      "10        ...         NaN    54881            en   \n",
      "20        ...         NaN      978            en   \n",
      "\n",
      "                                                                              \\\n",
      "                                                    license listens lyricist   \n",
      "track_id                                                                       \n",
      "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
      "3         Attribution-NonCommercial-ShareAlike 3.0 Inter...     514      NaN   \n",
      "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
      "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
      "20        Attribution-NonCommercial-NoDerivatives (aka M...     361      NaN   \n",
      "\n",
      "                                                 \n",
      "         number publisher tags            title  \n",
      "track_id                                         \n",
      "2             3       NaN   []             Food  \n",
      "3             4       NaN   []     Electric Ave  \n",
      "5             6       NaN   []       This World  \n",
      "10            1       NaN   []          Freeway  \n",
      "20            3       NaN   []  Spiritual Level  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tracks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_17884\\3966755446.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features_df = pd.read_csv('data/fma_metadata/features.csv', index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of features to genres for the small dataset saved to 'features_genre_mapping_small.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the features and metadata\n",
    "features_df = pd.read_csv('data/fma_metadata/features.csv', index_col=0)\n",
    "tracks_df = pd.read_csv('data/fma_metadata/tracks.csv', header=[0, 1], index_col=0)\n",
    "\n",
    "# Flatten the multi-level column names in tracks.csv\n",
    "tracks_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in tracks_df.columns]\n",
    "\n",
    "# Filter the small dataset (subset)\n",
    "small_tracks = tracks_df[tracks_df['set_subset'] == 'small']\n",
    "\n",
    "# Extract relevant columns: track_id, features, and genre\n",
    "small_tracks = small_tracks[['track_genre_top']].copy()\n",
    "small_tracks.index = small_tracks.index.astype(int)  # Ensure track_id is an integer\n",
    "\n",
    "# Merge features with genres\n",
    "mapping_df = features_df.merge(small_tracks, left_index=True, right_index=True)\n",
    "\n",
    "# Save the mapping to a new CSV file\n",
    "mapping_df.to_csv('features_genre_mapping_small.csv', index=True)\n",
    "\n",
    "print(\"Mapping of features to genres for the small dataset saved to 'features_genre_mapping_small.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_cens</th>\n",
       "      <th>chroma_cens.1</th>\n",
       "      <th>chroma_cens.2</th>\n",
       "      <th>chroma_cens.3</th>\n",
       "      <th>chroma_cens.4</th>\n",
       "      <th>chroma_cens.5</th>\n",
       "      <th>chroma_cens.6</th>\n",
       "      <th>chroma_cens.7</th>\n",
       "      <th>chroma_cens.8</th>\n",
       "      <th>chroma_cens.9</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz.40</th>\n",
       "      <th>tonnetz.41</th>\n",
       "      <th>zcr</th>\n",
       "      <th>zcr.1</th>\n",
       "      <th>zcr.2</th>\n",
       "      <th>zcr.3</th>\n",
       "      <th>zcr.4</th>\n",
       "      <th>zcr.5</th>\n",
       "      <th>zcr.6</th>\n",
       "      <th>track_genre_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.0000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.00000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.0</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918.000000</td>\n",
       "      <td>7918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7901.000000</td>\n",
       "      <td>7901.0000</td>\n",
       "      <td>7901.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7901.000000</td>\n",
       "      <td>7901.00000</td>\n",
       "      <td>7901.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7899.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7901.000000</td>\n",
       "      <td>1573.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>7897.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2.120035</td>\n",
       "      <td>-0.1481</td>\n",
       "      <td>0.687363</td>\n",
       "      <td>1.388522</td>\n",
       "      <td>-0.779828</td>\n",
       "      <td>-1.049356</td>\n",
       "      <td>-1.352663</td>\n",
       "      <td>-1.146229</td>\n",
       "      <td>0.13384</td>\n",
       "      <td>0.494833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>101.444832</td>\n",
       "      <td>0.385742</td>\n",
       "      <td>0.040447</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.669625</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>3648.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chroma_cens  chroma_cens.1  chroma_cens.2  chroma_cens.3  \\\n",
       "count   7918.000000      7918.0000    7918.000000    7918.000000   \n",
       "unique  7901.000000      7901.0000    7901.000000    7900.000000   \n",
       "top        2.120035        -0.1481       0.687363       1.388522   \n",
       "freq       6.000000         6.0000       6.000000       6.000000   \n",
       "\n",
       "        chroma_cens.4  chroma_cens.5  chroma_cens.6  chroma_cens.7  \\\n",
       "count     7918.000000    7918.000000    7918.000000    7918.000000   \n",
       "unique    7900.000000    7900.000000    7900.000000    7901.000000   \n",
       "top         -0.779828      -1.049356      -1.352663      -1.146229   \n",
       "freq         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "        chroma_cens.8  chroma_cens.9  ...   tonnetz.40   tonnetz.41  \\\n",
       "count      7918.00000    7918.000000  ...  7918.000000  7918.000000   \n",
       "unique     7901.00000    7901.000000  ...  7899.000000  7900.000000   \n",
       "top           0.13384       0.494833  ...     0.023668     0.022414   \n",
       "freq          6.00000       6.000000  ...     6.000000     6.000000   \n",
       "\n",
       "                zcr        zcr.1        zcr.2        zcr.3   zcr.4  \\\n",
       "count   7918.000000  7918.000000  7918.000000  7918.000000  7918.0   \n",
       "unique  7901.000000  1573.000000  7900.000000   343.000000    85.0   \n",
       "top      101.444832     0.385742     0.040447     0.033691     0.0   \n",
       "freq       6.000000    20.000000     6.000000    99.000000  3648.0   \n",
       "\n",
       "              zcr.5        zcr.6  track_genre_top  \n",
       "count   7918.000000  7918.000000             7918  \n",
       "unique  7900.000000  7897.000000                8  \n",
       "top        5.669625     0.026036       Electronic  \n",
       "freq       6.000000     6.000000             1000  \n",
       "\n",
       "[4 rows x 519 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7918, 518)\n",
      "Labels shape: (7918,)\n",
      "Genre mapping: {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3, 'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n"
     ]
    }
   ],
   "source": [
    "# Filter relevant features: mfcc_* and spectral_*\n",
    "# feature_columns = [col for col in mapping_df.columns if col.startswith('mfcc.') or col.startswith('spectral_')]\n",
    "feature_columns = [col for col in mapping_df.columns]\n",
    "\n",
    "X = mapping_df.drop(columns=['track_genre_top']).values\n",
    "\n",
    "# Encode the genre labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(mapping_df['track_genre_top'])  # Labels matrix\n",
    "\n",
    "# Check the shapes of the features and labels\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "# Optional: Save the label encoding mapping for later use\n",
    "genre_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Genre mapping:\", genre_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom Dataset class\n",
    "class GenreDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = GenreDataset(X_train, y_train)\n",
    "test_dataset = GenreDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network\n",
    "class GenreClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(GenreClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 518  # Number of input features\n",
    "num_classes = 8   # Number of classes\n",
    "model = GenreClassifier(input_size, num_classes=8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, labels in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Testing loop\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.4521, Train Accuracy: 0.4847\n",
      "Test Loss: 1.2609, Test Accuracy: 0.5612\n",
      "Epoch 2/20\n",
      "Train Loss: 1.1181, Train Accuracy: 0.6080\n",
      "Test Loss: 1.1971, Test Accuracy: 0.5903\n",
      "Epoch 3/20\n",
      "Train Loss: 0.9738, Train Accuracy: 0.6514\n",
      "Test Loss: 1.1885, Test Accuracy: 0.5966\n",
      "Epoch 4/20\n",
      "Train Loss: 0.8518, Train Accuracy: 0.7024\n",
      "Test Loss: 1.2233, Test Accuracy: 0.5896\n",
      "Epoch 5/20\n",
      "Train Loss: 0.7585, Train Accuracy: 0.7384\n",
      "Test Loss: 1.2281, Test Accuracy: 0.6061\n",
      "Epoch 6/20\n",
      "Train Loss: 0.6513, Train Accuracy: 0.7772\n",
      "Test Loss: 1.2678, Test Accuracy: 0.5979\n",
      "Epoch 7/20\n",
      "Train Loss: 0.5562, Train Accuracy: 0.8118\n",
      "Test Loss: 1.3424, Test Accuracy: 0.6048\n",
      "Epoch 8/20\n",
      "Train Loss: 0.4712, Train Accuracy: 0.8420\n",
      "Test Loss: 1.4261, Test Accuracy: 0.6067\n",
      "Epoch 9/20\n",
      "Train Loss: 0.3850, Train Accuracy: 0.8735\n",
      "Test Loss: 1.4868, Test Accuracy: 0.5934\n",
      "Epoch 10/20\n",
      "Train Loss: 0.3189, Train Accuracy: 0.9020\n",
      "Test Loss: 1.6245, Test Accuracy: 0.5953\n",
      "Epoch 11/20\n",
      "Train Loss: 0.2362, Train Accuracy: 0.9313\n",
      "Test Loss: 1.7547, Test Accuracy: 0.5922\n",
      "Epoch 12/20\n",
      "Train Loss: 0.1807, Train Accuracy: 0.9471\n",
      "Test Loss: 1.8530, Test Accuracy: 0.5909\n",
      "Epoch 13/20\n",
      "Train Loss: 0.1350, Train Accuracy: 0.9651\n",
      "Test Loss: 2.0017, Test Accuracy: 0.5859\n",
      "Epoch 14/20\n",
      "Train Loss: 0.1177, Train Accuracy: 0.9686\n",
      "Test Loss: 2.1387, Test Accuracy: 0.5859\n",
      "Epoch 15/20\n",
      "Train Loss: 0.1009, Train Accuracy: 0.9730\n",
      "Test Loss: 2.2478, Test Accuracy: 0.5878\n",
      "Epoch 16/20\n",
      "Train Loss: 0.0851, Train Accuracy: 0.9779\n",
      "Test Loss: 2.4011, Test Accuracy: 0.5903\n",
      "Epoch 17/20\n",
      "Train Loss: 0.1165, Train Accuracy: 0.9670\n",
      "Test Loss: 2.6224, Test Accuracy: 0.5789\n",
      "Epoch 18/20\n",
      "Train Loss: 0.1336, Train Accuracy: 0.9610\n",
      "Test Loss: 2.6199, Test Accuracy: 0.5833\n",
      "Epoch 19/20\n",
      "Train Loss: 0.0773, Train Accuracy: 0.9769\n",
      "Test Loss: 2.5974, Test Accuracy: 0.5890\n",
      "Epoch 20/20\n",
      "Train Loss: 0.0266, Train Accuracy: 0.9970\n",
      "Test Loss: 2.6850, Test Accuracy: 0.5909\n",
      "Model saved to 'genre_classifier.pth'\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'genre_classifier.pth')\n",
    "print(\"Model saved to 'genre_classifier.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track ID   Title                          True Genre      Predicted Genre\n",
      "----------------------------------------------------------------------\n",
      "1154       Hello Heartstring              Pop             Pop            \n",
      "416        Smyrna Snow Walk               Rock            Rock           \n",
      "1082       Nam Nhi-tu                     International   International  \n",
      "481        Council Bluffs                 Folk            Folk           \n",
      "891        Your One Mind                  Rock            Rock           \n",
      "564        The Sugar Society              Electronic      International  \n",
      "1620       Track 01                       Experimental    Rock           \n",
      "1525       Scovil                         International   International  \n",
      "458        Hunt Like Devil 4              Pop             Folk           \n",
      "1127       Do I Tingle? Up?               Rock            Pop            \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function to test the model with 10 random songs\n",
    "def test_random_songs(model, X, y, metadata_df, device, label_encoder):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Select 10 random indices from the test dataset\n",
    "    random_indices = random.sample(range(len(X)), 10)\n",
    "\n",
    "    # Get the corresponding features, true labels, and metadata\n",
    "    random_features = X[random_indices]\n",
    "    true_labels = y[random_indices].numpy()\n",
    "\n",
    "    # Use the original indices of the test set to retrieve metadata\n",
    "    metadata = metadata_df.iloc[random_indices]\n",
    "\n",
    "    # Move features to the appropriate device\n",
    "    random_features = random_features.to(device)\n",
    "\n",
    "    # Predict genres\n",
    "    with torch.no_grad():\n",
    "        outputs = model(random_features)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        predicted_labels = predicted_labels.cpu().numpy()  # Move predictions back to CPU\n",
    "\n",
    "    # Decode the true and predicted labels\n",
    "    true_genres = label_encoder.inverse_transform(true_labels)\n",
    "    predicted_genres = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"{'Track ID':<10} {'Title':<30} {'True Genre':<15} {'Predicted Genre':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(len(random_indices)):\n",
    "        track_id = metadata.index[i]\n",
    "        title = metadata.iloc[i]['track_title'] if 'track_title' in metadata.columns else \"Unknown\"\n",
    "        true_genre = true_genres[i]\n",
    "        predicted_genre = predicted_genres[i]\n",
    "        print(f\"{track_id:<10} {title:<30} {true_genre:<15} {predicted_genre:<15}\")\n",
    "\n",
    "# Example usage\n",
    "test_random_songs(model, X_test, y_test, tracks_df, device, label_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
